[
  {
    "filename": "68856e3fa0dada0102354c58_Frequency-based Substructuring using Scanning Laser Doppler Vibrometry (translated Frekvens-baseret substrukturering ved.pdf",
    "title": "Frequency-based Substructuring using Scanning Laser Doppler Vibrometry",
    "abstract": "Frequency-Based Substructuring is a method used to predict the dynamic behavior of an assembled mechanical system by coupling the frequency response functions of its individual components. Traditionally, vibration responses in Frequency -Based Substructuring are measured using accelerometers. This study explores the feasibility of using a Scanning Laser Doppler Vibrometer as a non -contact alternative. The instrument offers distinct advantages, such as the ability to capture vibration responses across a predetermined grid of points without physically contacting the structure. The thesis includes both a numerical simulation and a physical experiment, comparing the coupled frequency response functions of a benchmark structure (obtained via Frequency-Based Substructuring) to the reference. Results from the simulation demonstrate strong agreement between the coupled system and the reference. The physical experiment also shows good agreement, even though it is slightly lower . This discrepancy is primarily attributed to the excitation method (a piezoelectric actuator ), which is just as critical as the measurement technique for obtaining accurate vibration data."
  },
  {
    "filename": "68841cc3762f9c0102790a14_Parallel Compression Algorithms (translated Paralleliserede Kompressionsalgoritmer).pdf",
    "title": "Parallel Compression Algorithms",
    "abstract": "We study two algorithms relevant for designing a parallelised Lempel-Ziv-77 compression scheme. First, we optimise the All Nearest Smaller Values algorithm from (Berkman et al., 1993), and then we design a variant of it that is suitable for running on a GPU while performingO(n)work with O(log2(n))span on n lg(n) threads on a CREW PRAM. When implemented, our GPU version achieves a 4-5 times speed-up over our CPU version. We then design a GPU version of the precomputation of Lowest Common Ancestor queries described in (Schieber & Vishkin,1988) in order to answer Range Minimum Query queries in constant time. It performsO(n)work and has O( p nlog(n) )span on q n lg(n) − 1threads on a CREW PRAM. Page 5 of 57"
  },
  {
    "filename": "68841cc4b47df20102b023e0_Approximation Algorithms for Replenishment Problems with Fixed Turnover Times (translated Approksimations algoritmer til.pdf",
    "title": "Approximation Algorithms for Replenishment Problems with Fixed Turnover Times",
    "abstract": "In this thesis, we study a problem called Replenishment Problems with Fixed Turnover Times (RFTT). The problem was first presented in [1] and combines routing and schedul- ing, two already hard classes of problems. It models a network of clients who each store a commodity. The amount each client has stored depletes over time. A client should never run out of this commodity, so we must ensure that we visit each client and refill their stock often enough. How quickly stock depletes varies from client to client, and it is allowed to visit and refill a client way before the clients stocks runs out. In this thesis we, like in [1], study both the Min-A vg and Min-Max versions of the problem, where the objectives are to minimize average cost of a route and minimize the cost of the longest route respec- tively. We cover the approximation algorithms on trees for both metrics given by [1] and we improve the complexity of their pseudo-polynomial algorithm for Min-A vg on a path. We then give a polynomial time algorithm for Min-Max on cycles, a 4-approximation for Min-A vg on cycles and insight into how a pseudo-polynomial algorithm for Min-A vg on cycles might be achieved. Finally we combine the ideas from the tree algorithms and cycle algorithms to give approximation algorithms for graphs, where all cycles are disjoint. On these graphs we give an algorithm for finding optimal routes, a 6 + NC-approximation for Min-Max, where NC is the number of cycles in a graph, and a 4-approximation for Min-A vg. Approximation Algorithms for Replenishment Problems with Fixed Turnover Times ii"
  },
  {
    "filename": "68841cc6439dc00102b37cac_Assessment of solar energy in Greenland Analyzing potential and resource availability (translated Analyse af potentialet.pdf",
    "title": "Assessment of solar energy in Greenland Analyzing potential and resource availability",
    "abstract": "Abstract not found"
  },
  {
    "filename": "688179c3e3c31f0102091152_Chemically enhanced bioremediation of 1,2-cis-dichloroethylene in a limestone aquifer (translated Kemisk stimuleret bio-.pdf",
    "title": "Chemically enhanced bioremediation of 1,2-cis-dichloroethylene in a limestone aquifer",
    "abstract": "Groundwater contamination by chlorinated solvents, particularly cis-1,2-dichloroethylene (cDCE), poses a significant threat to drinking water resources, especially in fractured lime- stone aquifers. This thesis assess the potential of three remediation strategies: Biogeochemi- cal Reductive Dechlorination (BiRD), Enhanced Reductive Dechlorination (ERD), and their combined application to treat a cDCE-dominated contaminant plume at the Naverland site in Denmark. Laboratory-scale batch experiments were conducted using bioactive ground- water and limestone to simulate site-specific conditions. Four scenarios were tested: natural attenuation, GeoForm® Soluble (a ferrous sulfate-based amendment), KB-1® (a containing microbial consortium Dehalococcoides ), and a combination of GeoForm® and KB-1®. The results demonstrated that ERD using KB-1® was the most effective approach, achiev- ing complete dechlorination of cDCE to ethene with high degradation rates. Despite its the- oretical potential, BiRD produced no observable degradation of target compounds within the study’s duration due to delayed formation of reactive iron sulphide (FeS) and insuf- ficient reductive conditions. The combined treatment accelerated FeS formation through sulfate-reducing bacteria (SRB) in KB-1®. The high iron and sulphide concentrations from GeoForm® inhibited Dehalococcoides activity , significantly reducing degradation eﬀiciency. Despite this inhibition, the detection of vinyl chloride and ethene at low levels confirmed persistent biotic degradation.” These findings highlight the importance of redox control, amendment compatibility , and microbial resilience in remediation design. Given the site’s hydrogeology and buffering capacity , ERD using KB-1® is recommended for field-scale implementation. Keywords: Chlorinated ethenes, Groundwater treatment, Bioaugmentation, Aquifer geo- chemistry , Laboratory microcosms vii"
  },
  {
    "filename": "6882cb453a64980102753dbe_Inverse Reinforcement Learning for Decision Making in Autonomous Ship Navigation (translated Inverse Reinforcement Learn.pdf",
    "title": "Inverse Reinforcement Learning for Decision Making in Autonomous Ship Navigation",
    "abstract": "The shipping industry is progressing towards the fully autonomous operation of vessels. However, there are still many challenges in achieving safe and reliable decision making in confined and congested waterways. The present thesis contributes to this research area by investigating the use of Inverse Reinforcement Learning (IRL) for decision making in Autonomous Ship Navigation (ASN) . IRL is a promising approach since it not only en­ ables learning of decision making policies but also the inference of reward functions that encode the underlying motives of expert vessel captains. The primary objectives of this thesis were to first translate the publicly available Automatic Identification System (AIS) ­ data into a format that allowed for the application of IRL methods and to subsequently learn, evaluate and compare policies and reward functions for Goal­Only Navigation (GO­ Navigation) and Environment­Aware Navigation (EA­Navigation) derived by different IRL methods. First, the AIS­data has been analysed and preprocessed using maritime domain knowl­ edge. Based on the insights gained, the available information from the AIS­data has been embedded into a Markov Decision Process (MDP) . This entailed the implementation of a 2­ Degree of Freedom (DoF) kinematic vessel simulator, the development and evalu­ ation of two observation definitions as well as the development and evaluation of three distinct methods to infer actions from AIS­data. A graph­based observation definition and a Kalman filter­based approach for action inference were chosen. Three different algorithms ­ Behaviour Cloning (BC) , Adversarial Inverse Reinforcement Learning (AIRL) and Approximate Variational Reward Imitation Learning (AVRIL) ­ were evaluated on both navigation tasks. BC was used as a baseline and demonstrated decent waypoint­following behaviour and good signs of environmental awareness. It also helped establish that Graph Neural Networks (GNNs) are a superior choice for policy and reward network architectures in the EA­Navigation task. AIRL showed the best result in the GO­ Navigation setting with well­performing policies and plausible reward functions. In the EA­Navigation task, the learned policy showed insufficient behaviours, while the reward function was interpretable but only provided limited insights. AVRIL performed well for GO­Navigation but showed inconsistencies in the more complex task. High uncertainties and collapses to a standard normal distribution limited the interpretability of the reward distribution. Inverse Reinforcement Learning for Decision Making in Autonomous Ship Navigation iii"
  },
  {
    "filename": "688179cab4828e010294aa2b_Modelling price volatility in the maritime sector for decarbonization (translated Modellering af prisvolatilitet i den m.pdf",
    "title": "Modelling price volatility in the maritime sector for decarbonization",
    "abstract": "This thesis introduces an original integration of market dynamics into the bunker optimization module of the NavigaTE algorithm, developed within the Mærsk Mc­Kinney Møller Center for Zero Carbon Shipping. By replacing static fuel cost assumptions with a dynamic pricing mech­ anism informed by shadow prices and iterative convergence, the model captures fuel allocation decisions under realistic market constraints. This enhancement enables a more responsive and economically grounded representation of fuel distribution in the context of maritime de­ carbonisation, improving the fidelity of system level assessments under regulatory and supply limitations. Modelling Market Dynamics within the Maritime Sector iii"
  },
  {
    "filename": "68841cc293f4890102a19a57_Locally Consistent Parsing (translated Lokalt konstistent parsing).pdf",
    "title": "Locally Consistent Parsing",
    "abstract": "This thesis surveys different data structures, all using the concept oflocally consistent parsing. Locally consistent parsing is a way of process a string, S, of length n so that all identical substrings of a certain length, no matter their position in S, are treated the same way. Many problems related to string indexing can be solved within sublinear space using locally consistent data structures. We present several constructions of locally consistent partitionings. Two of these are based on prior work: the ( τ, δ)-partitioning set and the τ-synchronising set. Additionally, we introduce the (α, β, τ, ρ)-locally consistent set as a unifying framework to highlight the parallels and distinctions between the two existing partitionings. We demonstrate that given a τ-synchronising set, it is possible to construct a (τ, τ )-partitioning set in O \u0000 n τ \u0001 time. Furthermore, in the absence of periodic substrings, such a ( τ, τ )-partitioning set can be transformed into a (τ + 1)-synchronising set. This implies that one can use a deterministic O (n)-time construction of a τ-synchronising set, transform it into a ( τ, τ )-partitioning set in O \u0000 n τ \u0001 , and thereby obtain a faster construction than the previously suggested deterministic O (n log τ) approach. Continuing the literature survey of local consistency, we also cover the locally consistent grammar known as the signature grammar, a structure introduced in earlier literature. Using the main idea behind the signature grammars construction, we propose a new partitioning method called τ-local minimum set. Furthermore, two concepts of locality are introduced: index-based and block-based locality, and these are applied to the previously described partitionings. They are also used to clarify the difference between the problems which can be solved by the locally consistent partitionings with index-based locality properties and those solved by the signature grammar with block-based properties. Index- based locality ensures that when solving, for instance, problems similar to The Longest Common Extension Problem, it is possible to make very few look-ups in the original string and instead work on a much smaller string (of size n τ ) for most of the query. Block-based locality makes the original string superfluous and, in fact, works as a compression of the original string. It is possible to make string indexing queries on the compressed string. Finally, this thesis points to an inadequate part of the original correctness proof of the signature grammar’s string indexing query. We describe an example where the description in the paper would overlook an occurrence. We provide an updated query algorithm and prove that it works, while still preserving the runtime of the original algorithm. 2"
  },
  {
    "filename": "688179c467232d0102eacfc4_Bayesian Optimization for Hyperparameter Optimization in Linear Gaussian Models (translated Bayesiansk optimering til hy.pdf",
    "title": "Bayesian Optimization for Hyperparameter Optimization in Linear Gaussian Models",
    "abstract": "This report investigates the input estimation of linear Gaussian models using the prop­ erties of Gaussian processes. In particular, it demonstrates the advantages of using the Stable Spline (SS) kernel for system identification. In addition to this hyperparameter selection is performed by optimizing cost­functions corresponding to the Profile Marginal­ ized Likelihood (PML) and Generalized Cross­Validation (GCV) criteria, where Bayesian optimization is utilized to efficiently locate their optimum point. Furthermore, an analyt­ ical approach based on Singular Value Decomposition (SVD) is introduced to reduce a variable from the cost­functions, significantly improving the computational efficiency of evaluating the cost­function and ultimately locating the optimum point. Additionally, the report explores how combining the PML and GCV criteria can lead to improved fit­scores. However, experimental results indicate no clear pattern for how the combination should be weighted. Bayesian Optimization for Hyperparameter Optimization in Linear Gaussian Models iii"
  },
  {
    "filename": "6882cb49016f110102ce9a4e_Algorithms for Text Indexing (translated Algoritmer for tekstindeksering).pdf",
    "title": "Algorithms for Text Indexing",
    "abstract": "The text indexing problem [1, 18] is a central topic in computer science, highly addressed by many scientists and professionals throughout time. It plays a critical role in many modern sys- tems, especially in the field of databases, which need to handle and retrieve tons of information on a daily basis. The problem essentially deals with building efficient data structures for strings that would allow searching for online patterns. The ideal solution would show full efficiency by taking up both little space and building effort, while supporting fast operations. The current thesis proposes three new algorithms for the text indexing problem starting from the index structure of Ayad et al. [2], which uses anchors to come closer to the desired end goal. The first variant followed a naive strategy, the second used the benefits of akd-tree to improve the query times, and the last one adjusted the internal structure of the compact trie. The experimental evaluation indicates that searching times improve, but the space complexity remains more or less the same across the three algorithms. Most results of the thesis are similar to the ones of the index solution of Ayad et al. [2]. Specifically, the space of the data structure decreases as the number of anchors gets higher. The significance of these findings can be found in the benefits that anchors bring to the text indexing problem. Keywords: Algorithms, Text Indexing, Pattern Matching, Locally Consistent Anchors, Experi- mental Evaluation"
  }
]